# -*- coding: utf-8 -*-
"""FaceDetectModel.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kSDi4nGRRpnPPrac1DF-QCcLMTC4tG-x
"""

import kagglehub
import tensorflow as tf
import os
dataset_path = kagglehub.dataset_download('jasonhcwong/faces-ms1m-refine-v2-112x112-tfrecord')
print("Dataset downloaded to:", dataset_path)

# List files in the dataset directory
print("Files in dataset directory:")
if os.path.exists(dataset_path):
    files = os.listdir(dataset_path)
    for file in files:
        print(f"  {file}")
else:
    print("Dataset directory not found")

# 3. Load with correct path
file_pattern = f"{dataset_path}/faces_ms1m_refine_v2_112x112-*.tfrecord"
file_dataset = tf.data.Dataset.list_files(file_pattern)

# 4. Check if files were found
num_files = len(list(file_dataset))
print(f"Found {num_files} TFRecord files")

if num_files == 0:
    raise ValueError("No TFRecord files found! Check the download path.")
else:
    train_dataset = tf.data.TFRecordDataset(
        file_dataset,
        num_parallel_reads=tf.data.AUTOTUNE
    )

import numpy as np
import tensorflow as tf
from tensorflow.keras import regularizers, Model, mixed_precision
from tensorflow.keras.layers import Layer, Input, Conv2D, DepthwiseConv2D, ZeroPadding2D, BatchNormalization, ReLU, Add, Flatten
from tensorflow.keras import backend as K
import math

# Enable GPU memory growth
physical_devices = tf.config.list_physical_devices('GPU')
for device in physical_devices:
    tf.config.experimental.set_memory_growth(device, True)

# Mixed precision training
mixed_precision.set_global_policy('mixed_float16')

# Global batch size
GLOBAL_BATCH_SIZE = 512
print('Global batch size:', GLOBAL_BATCH_SIZE)

def advanced_augment(img):
    img = tf.image.random_flip_left_right(img)
    img = tf.image.random_brightness(img, max_delta=0.2)
    img = tf.image.random_contrast(img, lower=0.8, upper=1.2)
    img = tf.image.random_saturation(img, lower=0.8, upper=1.2)
    img = tf.image.random_hue(img, max_delta=0.1)
    img = tf.image.random_jpeg_quality(img, 75, 100)
    # Optionally add random crop, cutout, or gaussian noise
    return img

# Modified parse function to return simpler structure
def parse_function(example_proto, n_classes=85742):
    features = {
        'image_raw': tf.io.FixedLenFeature([], tf.string),
        'label': tf.io.FixedLenFeature([], tf.int64)
    }
    features = tf.io.parse_single_example(example_proto, features)

    # Image processing
    img = tf.image.decode_jpeg(features['image_raw'])
    img = tf.reshape(img, shape=(112, 112, 3))
    img = tf.cast(img, dtype=tf.float32)
    img = advanced_augment(img)  # <--- Use advanced augmentation
    img = tf.subtract(img, 128)
    img = tf.multiply(img, 0.0078125)

    # Label processing
    label = tf.cast(features['label'], tf.int64)
    label = tf.one_hot(label, n_classes)

    # Return as dictionary for clarity
    return {'image': img, 'label': label}

# Create dataset pipeline
file_pattern = os.path.join(dataset_path, "*.tfrecord")
train_dataset = tf.data.Dataset.list_files(file_pattern) \
    .interleave(
        lambda x: tf.data.TFRecordDataset(x),
        cycle_length=4,
        num_parallel_calls=tf.data.AUTOTUNE
    ) \
    .map(parse_function, num_parallel_calls=tf.data.AUTOTUNE) \
    .batch(GLOBAL_BATCH_SIZE) \
    .prefetch(tf.data.AUTOTUNE)

# Test the dataset
print("\nTesting dataset...")
for batch in train_dataset.take(1):
    print(f"Batch images shape: {batch['image'].shape}")
    print(f"Batch labels shape: {batch['label'].shape}")

class ArcFace(Layer):
    def __init__(self, n_classes=10, s=64.0, m=0.50, regularizer=None, **kwargs):
        super(ArcFace, self).__init__(**kwargs)
        self.n_classes = n_classes
        self.s = s
        self.m = m
        self.regularizer = regularizers.get(regularizer)

    def build(self, input_shape):
        self.W = self.add_weight(
            name='W',
            shape=(input_shape[0][-1], self.n_classes),
            initializer='glorot_uniform',
            trainable=True,
            regularizer=self.regularizer)
        super(ArcFace, self).build(input_shape[0])

    def call(self, inputs):
        cos_m = math.cos(self.m)
        sin_m = math.sin(self.m)
        mm = sin_m * self.m
        threshold = math.cos(math.pi - self.m)

        embedding, labels = inputs

        embedding_norm = tf.norm(embedding, axis=1, keepdims=True)
        embedding = embedding / embedding_norm

        weights = self.W
        weights_norm = tf.norm(weights, axis=0, keepdims=True)
        weights = weights / weights_norm

        cos_t = tf.matmul(embedding, weights)
        sin_t = tf.sqrt(1.0 - tf.square(cos_t))
        cos_mt = self.s * (cos_t * cos_m - sin_t * sin_m)

        cond = tf.cast(cos_t - threshold > 0, dtype=tf.bool)
        keep_val = self.s * (cos_t - mm)
        cos_mt = tf.where(cond, cos_mt, keep_val)

        mask = labels
        inv_mask = 1.0 - mask

        logits = self.s * cos_t * inv_mask + cos_mt * mask
        return tf.nn.softmax(logits)

    def get_config(self):
        return {'s': self.s, 'm': self.m, 'n_classes': self.n_classes}

def correct_pad(inputs, kernel_size):
    img_dim = 2 if tf.keras.backend.image_data_format() == 'channels_first' else 1
    input_size = tf.keras.backend.int_shape(inputs)[img_dim:(img_dim + 2)]
    if isinstance(kernel_size, int):
        kernel_size = (kernel_size, kernel_size)
    adjust = (1 - input_size[0] % 2, 1 - input_size[1] % 2)
    correct = (kernel_size[0] // 2, kernel_size[1] // 2)
    return ((correct[0] - adjust[0], correct[0]), (correct[1] - adjust[1], correct[1]))

def inverted_res_block(inputs, expansion, stride, filters, block_id):
    in_channels = tf.keras.backend.int_shape(inputs)[-1]
    pointwise_filters = filters
    x = inputs
    prefix = f'block_{block_id}_'

    x = Conv2D(expansion * in_channels, 1, padding='same', use_bias=False, name=prefix + 'expand')(x)
    x = BatchNormalization(name=prefix + 'expand_BN')(x)

    if stride == 2:
        x = ZeroPadding2D(padding=correct_pad(x, 3), name=prefix + 'pad')(x)
        x = DepthwiseConv2D(3, strides=stride, padding='same' if stride == 1 else 'valid', use_bias=False, name=prefix + 'depthwise')(x)
        x = BatchNormalization(name=prefix + 'depthwise_BN')(x)
        x = ReLU(6., name=prefix + 'depthwise_relu')(x)

    x = Conv2D(pointwise_filters, 1, padding='same', use_bias=False, name=prefix + 'project')(x)
    x = BatchNormalization(name=prefix + 'project_BN')(x)

    if in_channels == pointwise_filters and stride == 1:
        return Add(name=prefix + 'add')([inputs, x])
    return x

class L2Normalization(tf.keras.layers.Layer):
    def call(self, inputs):
        return tf.keras.backend.l2_normalize(inputs, axis=-1)

def mobilefacenet_arcface(n_classes=85742):

    weight_decay = 0.00005
    input = Input(shape=(112, 112, 3), name='input')
    y = Input(shape=(n_classes,), name='label')

    x = Conv2D(64, 3, strides=2, padding='same', use_bias=False, kernel_regularizer=regularizers.l2(weight_decay))(input)
    x = BatchNormalization()(x)
    x = ReLU()(x)

    x = DepthwiseConv2D(3, padding='same', use_bias=False)(x)
    x = BatchNormalization()(x)
    x = ReLU()(x)
    x = Conv2D(64, 1, padding='same', use_bias=False)(x)
    x = BatchNormalization()(x)

    x = inverted_res_block(x, 2, 2, 64, 0)
    x = inverted_res_block(x, 4, 2, 128, 1)
    x = inverted_res_block(x, 2, 1, 128, 2)
    x = inverted_res_block(x, 4, 2, 128, 3)
    x = inverted_res_block(x, 2, 1, 128, 4)

    x = Conv2D(512, 1, padding='same', use_bias=False)(x)
    x = BatchNormalization()(x)
    x = ReLU()(x)

    x = DepthwiseConv2D(7, padding='valid', use_bias=False)(x)
    x = BatchNormalization()(x)
    x = Conv2D(512, 1, padding='valid', use_bias=False)(x)
    x = BatchNormalization()(x)

    x = Conv2D(128, 1, padding='same', use_bias=False)(x)
    x = BatchNormalization()(x)
    x = Flatten()(x)

    x = L2Normalization(name="embedding")(x)
    output = ArcFace(n_classes=n_classes, dtype='float32')([x, y])

    return Model([input, y], output)

model = mobilefacenet_arcface()
opt = tf.keras.optimizers.Adam(beta_1=0.9, beta_2=0.999, epsilon=0.1)
model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])

def scheduler(epoch, lr):
    if epoch < 2:
        return 0.01
    elif epoch < 5:
        return 0.001
    else:
        return 0.0001

# Create checkpoint directory if it doesn't exist
os.makedirs("./ckpt", exist_ok=True)

checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(
      filepath="./ckpt/epoch_{epoch:02d}.keras",  # âœ… Ends with .keras
      save_weights_only=False,  # If saving full model
      monitor='val_accuracy',
      mode='auto',
      save_best_only=False
)

# Convert to float32 for inference/export
# Rebuild fp32 model
tf.keras.mixed_precision.set_global_policy("float32")
full_model_f32 = mobilefacenet_arcface(n_classes=85742)
full_model_f32.set_weights(model.get_weights())

# Extract input and output by referring directly to the layers
input_layer = full_model_f32.inputs[0]  # Correct input tensor
embedding_output = full_model_f32.get_layer("embedding").output  # Named layer

# Rebuild the output model for inference
outputModel = tf.keras.Model(inputs=input_layer, outputs=embedding_output, name="MobileFaceNetEmbedding")

# Save as Keras model (recommended for Keras models)
outputModel.save('./output_model')

# Convert to TFLite
converter = tf.lite.TFLiteConverter.from_keras_model(outputModel)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
# Optionally, provide a representative dataset for int8 quantization
def representative_data_gen():
    for _ in range(100):
        # yield a batch of input data as a numpy array
        yield [np.random.rand(1, 112, 112, 3).astype(np.float32)]
converter.representative_dataset = representative_data_gen
tflite_model = converter.convert()

with open('./output_model.tflite', 'wb') as f:
    f.write(tflite_model)

print("Model training and export completed successfully!")
print("Files created:")
print("- ./output_model (Keras model)")
print("- ./output_model.tflite (TFLite model)")
print("- ./ckpt/ (checkpoint directory)")